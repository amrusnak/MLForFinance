{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with the min-variance portfolio\n",
    "\n",
    "We will compute the min-variance portfolio using a gradient-descent algorithm and compare it to its closed-form version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need some data. We will download cryptoasset prices using the public API of Cryptocompare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "## cryptocompare endpoint for historical daily data\n",
    "## Documentation: https://min-api.cryptocompare.com/documentation?key=Historical&cat=dataHistoday\n",
    "url = \"https://min-api.cryptocompare.com/data/histoday?fsym={}&tsym=USD&limit={:d}\"\n",
    "\n",
    "## coin names and number of days we want\n",
    "coins = [\"BTC\", \"BCH\", \"ETH\", \"LTC\", \"XRP\"]\n",
    "n_coins = len(coins)\n",
    "n_day = 365*2\n",
    "\n",
    "## Get all time series\n",
    "dict_df = {}\n",
    "for coin in coins:\n",
    "    ## get the data for coin\n",
    "    res = requests.get(url.format(coin, n_day))\n",
    "    \n",
    "    ## reformat and get a dataframe indexed by time\n",
    "    df = pd.DataFrame(json.loads(res.content)['Data'])\\\n",
    "        .assign(time = lambda x: pd.to_datetime(x.time, unit='s'))\\\n",
    "        .assign(logret = lambda x: np.append(np.nan, np.diff(np.log(x.close))))\\\n",
    "        .set_index('time')\n",
    "        \n",
    "    ## you can make query as follows\n",
    "    # df[df.index.year >= 2019] ## data from 2019\n",
    "    # df[df.index.day == 15] ## 15-th of the month only\n",
    "    \n",
    "    ## save it in the dict\n",
    "    dict_df[coin] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, there is no train-test sets so we compute the covariance matrix once and treat it a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret = np.hstack([dict_df[coin].logret.values[1:].reshape(-1,1) for coin in coins])\n",
    "cov_mat = np.cov(log_ret, rowvar=False)\n",
    "#print('Covariance matrix:\\n', np.round(cov_mat, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closed-form min-variance portfolio\n",
    "\n",
    "The variance of the min-variance portfolio is\n",
    "$$\\sigma^2_{\\rm MV} = 1 / ({\\bf 1}^\\top \\Sigma^{-1} {\\bf 1})$$\n",
    "and the allocation weights are\n",
    "$$w_{\\rm MV} = (\\Sigma^{-1} {\\bf 1}) \\sigma^2_{\\rm MV}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Var weights:  [[83.26 -4.44 19.5  -7.75  9.43]]\n",
      "Min-Var volatility: 4.29%\n"
     ]
    }
   ],
   "source": [
    "ones = np.ones((n_coins, 1))\n",
    "inv_covmat = np.linalg.inv(cov_mat)\n",
    "var_mv = (1 / (ones.T @ inv_covmat @ ones)).squeeze()\n",
    "wgt_mv = (inv_covmat @ ones) * var_mv\n",
    "\n",
    "print('Min-Var weights: ', np.round(100*(wgt_mv.T), 2))\n",
    "print('Min-Var volatility: {:.2f}%'.format(100*var_mv**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-based approach\n",
    "\n",
    "First set the hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper-parameters\n",
    "learning_rate = 1.0\n",
    "n_steps = 5000\n",
    "pen_wgt = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build the model (=loss function), define the optimizer, initialize the variables, and train the model.\n",
    "\n",
    "**Question:** what do you think will happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 0]\n",
      "Weights:  [[19.65 19.39 19.52 19.48 19.47]]\n",
      "Loss:  0.027279116765012348\n",
      "Volatility: 4.86%\n",
      "Weights sum: 97.5086%\n",
      "-----\n",
      "[Step 1000]\n",
      "Weights:  [[-46.12 -51.31 -50.55 -52.78 -50.77]]\n",
      "Loss:  3.5313886384929045\n",
      "Volatility: 12.64%\n",
      "Weights sum: -251.5422%\n",
      "-----\n",
      "[Step 2000]\n",
      "Weights:  [[-49.49 -50.84 -50.67 -51.17 -50.65]]\n",
      "Loss:  3.544162188079894\n",
      "Volatility: 12.64%\n",
      "Weights sum: -252.8187%\n",
      "-----\n",
      "[Step 3000]\n",
      "Weights:  [[-50.23 -50.78 -50.64 -50.77 -50.66]]\n",
      "Loss:  3.546778265530467\n",
      "Volatility: 12.64%\n",
      "Weights sum: -253.0801%\n",
      "-----\n",
      "[Step 4000]\n",
      "Weights:  [[-50.39 -50.77 -50.63 -50.68 -50.67]]\n",
      "Loss:  3.5473570855993177\n",
      "Volatility: 12.64%\n",
      "Weights sum: -253.1379%\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "## build model\n",
    "tf.reset_default_graph()\n",
    "tsr_cov = tf.constant(cov_mat, name=\"cov_mat\")\n",
    "weights_init = np.full((n_coins,1), 1/n_coins)\n",
    "tsr_wgt = tf.Variable(initial_value=weights_init, name=\"weights\")\n",
    "tsr_var = tf.matmul(tf.transpose(tsr_wgt), tf.matmul(tsr_cov, tsr_wgt), name=\"var\")\n",
    "tsr_pen_wgt = tf.identity(tf.abs(tf.reduce_sum(tsr_wgt) - 1.0), name=\"sum_err\")\n",
    "tsr_loss = tsr_var + pen_wgt * tsr_pen_wgt\n",
    "\n",
    "## optimizer operation\n",
    "onestep_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(tsr_loss)\n",
    "\n",
    "## initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "## save some elements for investigation\n",
    "di = {'epoch' : np.zeros(n_steps),\n",
    "      'loss' : np.zeros(n_steps), \n",
    "      'vol' : np.zeros(n_steps), \n",
    "      'wgt_sum' : np.zeros(n_steps)}  \n",
    "\n",
    "## run\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(n_steps):\n",
    "        sess.run(onestep_op)\n",
    "        di['epoch'][i] = i\n",
    "        di['loss'][i] = tsr_loss.eval(session=sess).squeeze()\n",
    "        di['vol'][i] = (tsr_var.eval(session=sess)**0.5 * 100).squeeze()\n",
    "        di['wgt_sum'][i] = np.sum(tsr_wgt.eval(session=sess))\n",
    "        if i % 1e3 == 0 :\n",
    "            print(\"[Step {:d}]\".format(i))\n",
    "            print(\"Weights: \", np.round(100*(tsr_wgt.eval(session=sess).T), 2))\n",
    "            print(\"Loss: \", di['loss'][i])\n",
    "            print(\"Volatility: {:.2f}%\".format(di['vol'][i]))\n",
    "            print(\"Weights sum: {:.4f}%\".format(100*di['wgt_sum'][i]))\n",
    "            print(\"-\" * 5)\n",
    "\n",
    "    ## save final weights\n",
    "    wgt_gd = tsr_wgt.eval(session=sess)\n",
    "\n",
    "    ## save as DF\n",
    "    #print(pd.DataFrame(wgt_gd * 100, index = coins, columns = [\"weight_pct\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Var weights:\t [[83.26 -4.44 19.5  -7.75  9.43]]\n",
      "Min-Var weights TF:\t [[50.45 50.77 50.61 50.65 50.68]]\n",
      "Min-Var volatility:\t4.29%\n",
      "Min-Var volatility TF:\t12.64%\n"
     ]
    }
   ],
   "source": [
    "var_gd = (wgt_gd.T @ cov_mat @ wgt_gd).squeeze()\n",
    "\n",
    "print('Min-Var weights:\\t', np.round(100*(wgt_mv.T), 2))\n",
    "print('Min-Var weights TF:\\t', np.round(100*(wgt_gd.T), 2))\n",
    "print('Min-Var volatility:\\t{:.2f}%'.format(100*var_mv**0.5))\n",
    "print('Min-Var volatility TF:\\t{:.2f}%'.format(100*var_gd**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the metrics during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotnine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d5fdea1a7be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplotnine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mggplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgeom_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotnine'"
     ]
    }
   ],
   "source": [
    "from plotnine import ggplot, aes, geom_line\n",
    "\n",
    "df = pd.DataFrame(di)\n",
    "\n",
    "print(ggplot(df, aes(x='epoch', y='loss')) + geom_line())\n",
    "print(ggplot(df, aes(x='epoch', y='vol')) + geom_line())\n",
    "print(ggplot(df, aes(x='epoch', y='wgt_sum')) + geom_line())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "\n",
    "Evaluate:\n",
    "* split the data into train-test sets.\n",
    "* compare the in- and out-of-sample performance of the min-variance portfolio.\n",
    "* compare with the min-variance portfolio from the test set (best ex-post).\n",
    "\n",
    "Adjust portfolio:\n",
    "* construct a long-only portfolio (non-negative weights).\n",
    "* construct a sparse allocation portfolio (e.g. only 3 stocks).\n",
    "* construct a portfolio with a maximum absolute weight distance (e.g. 50%) with respect to the equiweighted portfolio.\n",
    "* construct the mean-variance portfolio (e.g. given a target return level).\n",
    "\n",
    "Improve the algorithm (open subject):\n",
    "* compute and display the covariance matrix over time (e.g. rolling window).\n",
    "* modify the methodology to (try to) reduce the out-of-sample variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
