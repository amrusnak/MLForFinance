{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option pricing function approximation with ANN\n",
    "\n",
    "We first make some tools to price some European call options, and to generate some random sample of options prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "def bsm_eucall_price(S, K, tau, sigma, r=0, d=0):\n",
    "    '''Black-Scholes-Merton call option price'''\n",
    "    d1 = (np.log(S/K) + (r-d + 0.5*sigma**2)*tau)/(sigma*tau**0.5)\n",
    "    d2 = d1 - sigma*tau**0.5\n",
    "    price = np.exp(-d*tau)*S*norm.cdf(d1) -K*np.exp(-r*tau)*norm.cdf(d2)\n",
    "    return(price)\n",
    "\n",
    "## generate some parameters and option prices\n",
    "##     - S = 1.0 : the underlying price is equal to one\n",
    "##     - r = d = 0 : no risk-free rate or interest rate\n",
    "def call_option_generator(n_sample, \n",
    "                          tau_range=[1/12, 1/2], \n",
    "                          sigmadev=2,\n",
    "                          sigma_range=[0.1, 0.5]):\n",
    "    '''\n",
    "    generate random parameters and compute prices:\n",
    "        - sigma, tau: uniformely\n",
    "        - log(K/S): uniformely on +/-sigmadev*sigma*tau**0.5\n",
    "    '''\n",
    "    x = np.zeros([n_sample, 4], dtype='float')\n",
    "    x[:,1] = np.random.uniform(tau_range[0], tau_range[1], n_sample)\n",
    "    x[:,2] = np.random.uniform(sigma_range[0], sigma_range[1], n_sample)\n",
    "    x[:,0] = np.random.uniform(-sigmadev, sigmadev, n_sample)\n",
    "    x[:,0] = np.exp(x[:,2]*x[:,1]**0.5*x[:,0])\n",
    "    ## price options\n",
    "    ifunc = lambda x: bsm_eucall_price(1.0, x[0], x[1], x[2])\n",
    "    x[:,3] = np.apply_along_axis(ifunc, 1, x[:,0:3])\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a data sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>tau</th>\n",
       "      <th>sigma</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.020312</td>\n",
       "      <td>0.290610</td>\n",
       "      <td>0.299600</td>\n",
       "      <td>0.089041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.204878</td>\n",
       "      <td>0.120976</td>\n",
       "      <td>0.114501</td>\n",
       "      <td>0.094868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.526479</td>\n",
       "      <td>0.083362</td>\n",
       "      <td>0.100050</td>\n",
       "      <td>0.000412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.879320</td>\n",
       "      <td>0.184968</td>\n",
       "      <td>0.197257</td>\n",
       "      <td>0.012639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.005153</td>\n",
       "      <td>0.292374</td>\n",
       "      <td>0.301872</td>\n",
       "      <td>0.052653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.137676</td>\n",
       "      <td>0.393661</td>\n",
       "      <td>0.397180</td>\n",
       "      <td>0.139674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.906169</td>\n",
       "      <td>0.499954</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.475728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 K          tau        sigma        price\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000\n",
       "mean      1.020312     0.290610     0.299600     0.089041\n",
       "std       0.204878     0.120976     0.114501     0.094868\n",
       "min       0.526479     0.083362     0.100050     0.000412\n",
       "25%       0.879320     0.184968     0.197257     0.012639\n",
       "50%       1.005153     0.292374     0.301872     0.052653\n",
       "75%       1.137676     0.393661     0.397180     0.139674\n",
       "max       1.906169     0.499954     0.499750     0.475728"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_sample = 5000\n",
    "np.random.seed(123)\n",
    "data = call_option_generator(n_sample)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(data[:,0], data[:,1], s=0.5, c=-data[:,2])\n",
    "plt.gray()\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('tau')\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(data, columns=['K', 'tau', 'sigma', 'price'])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = data[:,3]\n",
    "x = data[:,0:3]\n",
    "\n",
    "plt.hist(y)\n",
    "plt.xlabel('option price')\n",
    "plt.ylabel('number of observations')\n",
    "plt.show()\n",
    "\n",
    "## make train and test datasets\n",
    "test_size = 0.20\n",
    "random_state = 123\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to build an ANN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alexander/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_ann_model(input_dim=3, \n",
    "                    n_layer=2, \n",
    "                    n_neuron=20):\n",
    "    ## another way to buid a keras model\n",
    "    inputs = keras.Input(shape=(input_dim,), name='params')\n",
    "    x = inputs\n",
    "    for i in range(n_layer):\n",
    "        x = layers.Dense(units=n_neuron, \n",
    "                         activation='relu',\n",
    "                         use_bias=True,\n",
    "                         kernel_initializer='glorot_uniform',\n",
    "                         bias_initializer='zeros',\n",
    "                         kernel_regularizer=None,\n",
    "                         bias_regularizer=None,\n",
    "                         activity_regularizer=None,\n",
    "                         kernel_constraint=None,\n",
    "                         bias_constraint=None,\n",
    "                         name= 'hlayer_' + str(1+i)\n",
    "                         )(x)\n",
    "    outputs = layers.Dense(1, name='price')(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='bsm_model')\n",
    "    ## compile the model\n",
    "    model.compile(optimizer='sgd', loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1014 14:19:03.443097 140300613539648 deprecation.py:506] From /home/alexander/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bsm_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "params (InputLayer)          [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "hlayer_1 (Dense)             (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "price (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 161\n",
      "Trainable params: 161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "4000/4000 [==============================] - 0s 47us/sample - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 2/100\n",
      "4000/4000 [==============================] - 0s 26us/sample - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
      "Epoch 3/100\n",
      "4000/4000 [==============================] - 0s 28us/sample - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "Epoch 4/100\n",
      "4000/4000 [==============================] - 0s 28us/sample - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 5/100\n",
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 6/100\n",
      "4000/4000 [==============================] - 0s 18us/sample - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
      "Epoch 7/100\n",
      "4000/4000 [==============================] - 0s 21us/sample - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 8/100\n",
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 9/100\n",
      "4000/4000 [==============================] - 0s 22us/sample - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0057 - val_mean_squared_error: 0.0057\n",
      "Epoch 10/100\n",
      "4000/4000 [==============================] - 0s 18us/sample - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0054 - val_mean_squared_error: 0.0054\n",
      "Epoch 11/100\n",
      "4000/4000 [==============================] - 0s 24us/sample - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0052 - val_mean_squared_error: 0.0052\n",
      "Epoch 12/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0049 - val_mean_squared_error: 0.0049\n",
      "Epoch 13/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 14/100\n",
      "4000/4000 [==============================] - 0s 16us/sample - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0045 - val_mean_squared_error: 0.0045\n",
      "Epoch 15/100\n",
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0043 - val_mean_squared_error: 0.0043\n",
      "Epoch 16/100\n",
      "4000/4000 [==============================] - 0s 18us/sample - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 17/100\n",
      "4000/4000 [==============================] - 0s 16us/sample - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "Epoch 18/100\n",
      "4000/4000 [==============================] - 0s 15us/sample - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 19/100\n",
      "4000/4000 [==============================] - 0s 24us/sample - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 20/100\n",
      "4000/4000 [==============================] - 0s 25us/sample - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 21/100\n",
      "4000/4000 [==============================] - 0s 19us/sample - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 22/100\n",
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 23/100\n",
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Epoch 24/100\n",
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 25/100\n",
      "4000/4000 [==============================] - 0s 29us/sample - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 26/100\n",
      "4000/4000 [==============================] - 0s 26us/sample - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 27/100\n",
      "4000/4000 [==============================] - 0s 30us/sample - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 28/100\n",
      "4000/4000 [==============================] - 0s 24us/sample - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 29/100\n",
      "4000/4000 [==============================] - 0s 17us/sample - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 30/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 31/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 32/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 33/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 34/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 35/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 36/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 37/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 38/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 39/100\n",
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 40/100\n",
      "4000/4000 [==============================] - 0s 19us/sample - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Epoch 41/100\n",
      "4000/4000 [==============================] - 0s 16us/sample - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 42/100\n",
      "4000/4000 [==============================] - 0s 15us/sample - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 43/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 44/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 46/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 47/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 48/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 49/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 50/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 51/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 52/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 53/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 54/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 55/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 56/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 57/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 58/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 59/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 60/100\n",
      "4000/4000 [==============================] - 0s 16us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 61/100\n",
      "4000/4000 [==============================] - 0s 16us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 62/100\n",
      "4000/4000 [==============================] - 0s 15us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 63/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 64/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 65/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 66/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 67/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 68/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 69/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 70/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 71/100\n",
      "4000/4000 [==============================] - 0s 18us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 72/100\n",
      "4000/4000 [==============================] - 0s 15us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 73/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 74/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 75/100\n",
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 76/100\n",
      "4000/4000 [==============================] - 0s 18us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 77/100\n",
      "4000/4000 [==============================] - 0s 15us/sample - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 78/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 79/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 80/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 81/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 82/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 83/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 84/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 85/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 86/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 87/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 88/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 89/100\n",
      "4000/4000 [==============================] - 0s 17us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 90/100\n",
      "4000/4000 [==============================] - 0s 15us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 91/100\n",
      "4000/4000 [==============================] - 0s 17us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 92/100\n",
      "4000/4000 [==============================] - 0s 15us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 20us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 94/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 95/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 96/100\n",
      "4000/4000 [==============================] - 0s 11us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 97/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 98/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 99/100\n",
      "4000/4000 [==============================] - 0s 10us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 100/100\n",
      "4000/4000 [==============================] - 0s 12us/sample - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n"
     ]
    }
   ],
   "source": [
    "model = build_ann_model(input_dim=3, n_layer=1, n_neuron=32) \n",
    "model.summary()\n",
    "\n",
    "## params\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test)) ## val = set here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display fit and get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "history dict: dict_keys(['loss', 'mean_squared_error', 'val_loss', 'val_mean_squared_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "1000/1000 [==============================] - 0s 10us/sample - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "test loss, test acc: [0.0010785013297572733, 0.0010785013]\n",
      "\n",
      "# Generate predictions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.086728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.084991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-0.109343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.021822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.070982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.143081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.373983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             price\n",
       "count  1000.000000\n",
       "mean      0.086728\n",
       "std       0.084991\n",
       "min      -0.109343\n",
       "25%       0.021822\n",
       "50%       0.070982\n",
       "75%       0.143081\n",
       "max       0.373983"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# history = loss values and metric values during training\n",
    "print('\\nhistory dict:', history.history.keys())\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.epoch, np.array(history.history['mean_squared_error'])**0.5)\n",
    "plt.ylim(0, 0.1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.epoch, np.array(history.history['val_mean_squared_error'])**0.5)\n",
    "plt.ylim(0, 0.1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n",
    "\n",
    "# evaluate\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print('test loss, test acc:', results)\n",
    "\n",
    "# predictions\n",
    "print('\\n# Generate predictions')\n",
    "predictions = model.predict(x_test[:,0:3])\n",
    "pd.DataFrame({'price' : predictions.squeeze()}).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* What do remark about the price prediction values? Are some values possible? How can you arrange that?\n",
    "* Are the relative price errors the same? How can arrange/engineer that?\n",
    "* Build, train, and evaluate models with different features\n",
    "    * number of layers and number of parameters\n",
    "    * optimizer choice (e.g. SGD versus Adam)\n",
    "    * with and without dropout\n",
    "    * with and without parameter regularization\n",
    "* Which model is the best?\n",
    "* If you can (computationally speaking) enlarge the parameters range and number of parameter sets. Is your best model the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sgd', 1, True)\n",
      "('sgd', 1, False)\n",
      "('sgd', 2, True)\n",
      "('sgd', 2, False)\n",
      "('sgd', 3, True)\n",
      "('sgd', 3, False)\n",
      "('adam', 1, True)\n",
      "('adam', 1, False)\n",
      "('adam', 2, True)\n",
      "('adam', 2, False)\n",
      "('adam', 3, True)\n",
      "('adam', 3, False)\n"
     ]
    }
   ],
   "source": [
    "# a useful function to create parameter sets\n",
    "import itertools\n",
    "\n",
    "param_list = [\n",
    "    ['sgd', 'adam'],\n",
    "    [1, 2, 3],\n",
    "    [True, False]\n",
    "]\n",
    "\n",
    "## the star '*' is important here\n",
    "for element in itertools.product(*param_list):\n",
    "    print(element)\n",
    "    model = build_ann_model(input_dim=3, n_layer=1, n_neuron=32) \n",
    "    model.summary()\n",
    "\n",
    "    ## params\n",
    "    batch_size = 128\n",
    "    epochs = 100\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_test, y_test)) ## val = set here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
