{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series prediction with RNNs\n",
    "\n",
    "In this notebook we will implement a simple RNN to male predictions on the future value of a univariate time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Dense, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and display data\n",
    "\n",
    "Let's volontary choose a difficult time series with seasonality. By default RNNs are not equipped to handle seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pandas_datareader as pdr\n",
    "import matplotlib as plt\n",
    "\n",
    "start = dt.datetime(1950,1,1)\n",
    "end = dt.datetime(2019,1,1)\n",
    "data = pdr.get_data_fred('UNRATENSA', start=start, end=end)\n",
    "data.plot(figsize=(16, 9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the hypothesis that the time series is not stationnary with the Dickey-Fuller GLS testand the Phillips-Perron test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch.unitroot import DFGLS, PhillipsPerron\n",
    "\n",
    "dfgls = DFGLS(data['UNRATENSA'])\n",
    "print(dfgls.summary().as_text())\n",
    "\n",
    "pp = PhillipsPerron(data['UNRATENSA'])\n",
    "print(pp.summary().as_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMA\n",
    "\n",
    "Let's first see how a standar model would performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "## ad-hoc split of the data\n",
    "y_all = data['UNRATENSA']\n",
    "y_train0 = y_all[:'2010-01-01']\n",
    "y_test0 = y_all['2010-01-01':]\n",
    "\n",
    "## compute test size for later\n",
    "test_size = 1 - len(y_train0)/len(y_all)\n",
    "print(\"test size is {}%\".format(int(test_size*100)))\n",
    "\n",
    "## make and train the model\n",
    "mod = sm.tsa.statespace.SARIMAX(y_train0,\n",
    "                                order=None, ## TODO\n",
    "                                seasonal_order=None, ## TODO\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "\n",
    "## display results\n",
    "print(results.summary().tables[1])\n",
    "results.plot_diagnostics(figsize=(15, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in-sample one-step predictions\n",
    "pred = results.get_prediction(start=pd.to_datetime('2000-01-01'), dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "\n",
    "ax = y_all['2000-01-01':].plot(figsize=(16, 9))\n",
    "pred.predicted_mean.plot(ax=ax, label='one-step ahead Forecast', alpha=.7)\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## out-of-sample multiple-step forecast\n",
    "pred = results.get_forecast(steps=12*9)\n",
    "pred_ci = pred.conf_int()\n",
    "\n",
    "ax = y_all['2000-01-01':].plot(figsize=(16, 9))\n",
    "pred.predicted_mean.plot(ax=ax, label='multiple-step ahead Forecast', alpha=.7)\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "We now build an RNN similarly as in the warmup notebook. Let's first prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## it is good practice to center and normalize your data with ML models\n",
    "## if not, it may take a long time before the parameters converge to the right level and scale\n",
    "\n",
    "def prepare_univariate_ts(ts):\n",
    "    n = len(ts)\n",
    "    ts = ts / ts[0] - 1\n",
    "    data = ts[0:(n-1)]\n",
    "    labels = ts[1:n]\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "X, y = prepare_univariate_ts(data['UNRATENSA'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=test_size, ## get the same split\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=False ## THIS IS IMPORTANT FOR TIME SERIES!!!\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build the model and train a RNN. Keep in mind that we want to make out-of-sample prediction later. We will manually set the initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "def build_model(ydim, hdim=1):\n",
    "    ## hdim is the dimension of the RNN hidden layer\n",
    "    \n",
    "    ## 2 inputs:\n",
    "    input1 = Input(shape=(ydim, 1)) ## x_t time series\n",
    "    input2 = Input(shape=(hdim))    ## h_0 initial state\n",
    "    \n",
    "    ## TODO\n",
    "    ## 2 outputs the sequence of prediction, and the latent state\n",
    "    \n",
    "    return model\n",
    "\n",
    "hdim = 20\n",
    "model = build_model(ydim=len(y_train), hdim=hdim)\n",
    "\n",
    "## display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has two outputs, so there are special care needed when compiling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify the optimizer and loss function\n",
    "model.compile(optimizer='adam', \n",
    "              loss=None, ## TODO\n",
    "             )\n",
    "\n",
    "## prepare the data for training\n",
    "x_input = [X_train.reshape(1,-1,1), ## (1 TS, many months, 1 feature)\n",
    "           np.array([0.0]*hdim).reshape(1,hdim) ## initial hidden states\n",
    "           ]\n",
    "y_input = [y_train.reshape(1,-1,1),\n",
    "           np.zeros((1,hdim)) ## not used\n",
    "          ]\n",
    "\n",
    "## train\n",
    "history = model.fit(x=x_input, \n",
    "                    y=y_input, \n",
    "                    epochs=200\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in-sample predictions\n",
    "y_pred, h_last = model.predict(x_input)\n",
    "\n",
    "## in-sample one-step predictions\n",
    "pred = pd.Series((1 + y_pred.reshape(-1))*y_all[0],  ## need to shift and scale\n",
    "                 y_all[:'2010-01-01'].index[1:]\n",
    "                )\n",
    "\n",
    "ax = y_all['2000-01-01':].plot(figsize=(16, 9))\n",
    "pred['2000-01-01':].plot(ax=ax, label='one-step ahead Forecast', alpha=.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## out-of-sample multiple-step forecast\n",
    "\n",
    "## make a model to perform one-step predictions\n",
    "model_onestep = build_model(ydim=1, hdim=hdim)\n",
    "\n",
    "## transfer weights from trained model\n",
    "model_onestep.set_weights([w for w in model.get_weights()])\n",
    "\n",
    "## loop to make multiple steps predictions\n",
    "pred = []\n",
    "ht = h_last\n",
    "yt = X_test[0]\n",
    "for t in range(12*9):\n",
    "    data = [yt.reshape(1,1,1), ht]\n",
    "    yt, ht = model_onestep.predict(data)\n",
    "    pred.append(yt.squeeze())\n",
    "\n",
    "## reshape into a Series\n",
    "pred = np.asarray(pred)    \n",
    "pred = pd.Series((1 + pred.reshape(-1))*y_all[0],  ## need to shift and scale\n",
    "                 y_all['2010-01-01':].index[1:]\n",
    "                )\n",
    "\n",
    "## make plot\n",
    "ax = y_all['2000-01-01':].plot(figsize=(16, 9))\n",
    "pred.plot(ax=ax, label='multiple-step ahead Forecast', alpha=.7)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
